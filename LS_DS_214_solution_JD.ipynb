{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGnB0Lhq5-QC"
      },
      "source": [
        "BloomTech Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 4*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OPMSew75-QH"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Block\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from category_encoders import OneHotEncoder\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "id": "aphrmN0JCZej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp05fy5Z5-QI"
      },
      "source": [
        "# Module Project: Logistic Regression\n",
        "\n",
        "Do you like burritos? ðŸŒ¯ You're in luck then, because in this project you'll create a model to predict whether a burrito is `'Great'`.\n",
        "\n",
        "The dataset for this assignment comes from [Scott Cole](https://srcole.github.io/100burritos/), a San Diego-based data scientist and burrito enthusiast. \n",
        "\n",
        "## Directions\n",
        "\n",
        "The tasks for this project are the following:\n",
        "\n",
        "- **Task 1:** Import `csv` file using `wrangle` function.\n",
        "- **Task 2:** Conduct exploratory data analysis (EDA), and modify `wrangle` function .\n",
        "- **Task 3:** Split data into feature matrix `X` and target vector `y`.\n",
        "- **Task 4:** Split feature matrix `X` and target vector `y` into training and test sets.\n",
        "- **Task 5:** Establish the baseline accuracy score for your dataset.\n",
        "- **Task 6:** Build `model_logr` using a pipeline that includes three transfomers and `LogisticRegression` predictor. Train model on `X_train` and `X_test`.\n",
        "- **Task 7:** Calculate the training and test accuracy score for your model.\n",
        "- **Task 8:** Create a horizontal bar chart showing the 10 most influencial features for your  model. \n",
        "- **Task 9:** Demonstrate and explain the differences between `model_lr.predict()` and `model_lr.predict_proba()`.\n",
        "\n",
        "**Note** \n",
        "\n",
        "You should limit yourself to the following libraries:\n",
        "\n",
        "- `category_encoders`\n",
        "- `matplotlib`\n",
        "- `pandas`\n",
        "- `sklearn`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHMMAuT05-QK"
      },
      "source": [
        "# I. Wrangle Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8i5E7kat5-QK"
      },
      "outputs": [],
      "source": [
        "def wrangle(filepath):\n",
        "    # Import w/ DateTimeIndex\n",
        "    df = pd.read_csv(filepath, parse_dates=['Date'],\n",
        "                     index_col='Date')\n",
        "    \n",
        "    # Drop unrated burritos\n",
        "    df.dropna(subset=['overall'], inplace=True)\n",
        "    \n",
        "    # Derive binary classification target:\n",
        "    # We define a 'Great' burrito as having an\n",
        "    # overall rating of 4 or higher, on a 5 point scale\n",
        "    df['Great'] = (df['overall'] >= 4).astype(int)\n",
        "    \n",
        "    # Drop high cardinality categoricals\n",
        "    df = df.drop(columns=['Notes', 'Location', 'Address', 'URL', 'Neighborhood'])\n",
        "    \n",
        "    # Drop columns to prevent \"leakage\"\n",
        "    df = df.drop(columns=['Rec', 'overall'])\n",
        "\n",
        "    # Binary encoding column fixes\n",
        "    yes_cols = ['Chips']\n",
        "    bin_cols = ['Unreliable', 'NonSD', 'Beef', 'Pico', 'Guac', 'Cheese','Fries', 'Sour cream', 'Pork', 'Chicken', 'Shrimp',\n",
        "                'Fish', 'Rice', 'Beans', 'Lettuce', 'Tomato', 'Bell peper', 'Carrots', 'Cabbage', 'Sauce', 'Salsa.1', 'Cilantro', \n",
        "                'Onion', 'Taquito', 'Pineapple', 'Ham', 'Chile relleno', 'Nopales', 'Lobster', 'Queso', 'Egg', 'Mushroom', 'Bacon', \n",
        "                'Sushi', 'Avocado', 'Corn', 'Zucchini']\n",
        "\n",
        "    for col in bin_cols:\n",
        "      df[col] = [1 if (str(i).lower() == 'x') else 0 for i in df[col]]\n",
        "    for col in yes_cols:\n",
        "      df[col] = [1 if (str(y).lower() == 'yes') else 0 for y in df[col]]\n",
        "\n",
        "    # Dissect Burrito column into dummy columns\n",
        "    bur_types = ['california', 'asada', 'surf', 'carnitas']\n",
        "    for btype in bur_types:\n",
        "      df[btype] = [1 if (str(b).casefold().find(btype) != -1) else 0 for b in df['Burrito']]\n",
        "    df.drop(columns=['Burrito'], inplace=True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "filepath = DATA_PATH + 'burritos/burritos.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBQDrK7Q5-QL"
      },
      "source": [
        "**Task 1:** Use the above `wrangle` function to import the `burritos.csv` file into a DataFrame named `df`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ez1OnmAp5-QM"
      },
      "outputs": [],
      "source": [
        "filepath = DATA_PATH + 'burritos/burritos.csv'\n",
        "df = wrangle(filepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqpfK_Ep5-QN"
      },
      "source": [
        "During your exploratory data analysis, note that there are several columns whose data type is `object` but that seem to be a binary encoding. For example, `df['Beef'].head()` returns:\n",
        "\n",
        "```\n",
        "0      x\n",
        "1      x\n",
        "2    NaN\n",
        "3      x\n",
        "4      x\n",
        "Name: Beef, dtype: object\n",
        "```\n",
        "\n",
        "**Task 2:** Change the `wrangle` function so that these columns are properly encoded as `0` and `1`s. Be sure your code handles upper- and lowercase `X`s, and `NaN`s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6dha4oB5-QN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f4a16b-ad12-482a-e58e-58cba0c28f4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4323040380047506"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "# Conduct your exploratory data analysis here\n",
        "# And modify the `wrangle` function above.\n",
        "pd.options.display.max_columns=60\n",
        "df.head(15)\n",
        "#type(df.index)\n",
        "#df.isna().sum()\n",
        "#df['Great'].sum()/len(df['Great'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7FmNqEa5-QO"
      },
      "source": [
        "If you explore the `'Burrito'` column of `df`, you'll notice that it's a high-cardinality categorical feature. You'll also notice that there's a lot of overlap between the categories. \n",
        "\n",
        "**Stretch Goal:** Change the `wrangle` function above so that it engineers four new features: `'california'`, `'asada'`, `'surf'`, and `'carnitas'`. Each row should have a `1` or `0` based on the text information in the `'Burrito'` column. For example, here's how the first 5 rows of the dataset would look.\n",
        "\n",
        "| **Burrito** | **california** | **asada** | **surf** | **carnitas** |\n",
        "| :---------- | :------------: | :-------: | :------: | :----------: |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "|  Carnitas   |       0        |     0     |    0     |      1       |\n",
        "| Carne asada |       0        |     1     |    0     |      0       |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "\n",
        "**Note:** Be sure to also drop the `'Burrito'` once you've engineered your new features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjQ_mvdO5-QP"
      },
      "outputs": [],
      "source": [
        "# Conduct your exploratory data analysis here\n",
        "# And modify the `wrangle` function above.\n",
        "#df = pd.get_dummies(df, columns=['Burrito']) <- too many columns\n",
        "pd.options.display.max_columns=65\n",
        "df.head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU3W5ZLK5-QP"
      },
      "source": [
        "# II. Split Data\n",
        "\n",
        "**Task 3:** Split your dataset into the feature matrix `X` and the target vector `y`. You want to predict `'Great'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYIiG9Jp5-QQ"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=['Great'])\n",
        "y = df['Great']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTT1WO4A5-QQ"
      },
      "source": [
        "**Task 4:** Split `X` and `y` into a training set (`X_train`, `y_train`) and a test set (`X_test`, `y_test`).\n",
        "\n",
        "- Your training set should include data from 2016 through 2017. \n",
        "- Your test set should include data from 2018 and later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwWMQz655-QR"
      },
      "outputs": [],
      "source": [
        "date_mask = X.index < pd.Timestamp(\"2018\")\n",
        "X_train, y_train = X.loc[date_mask], y.loc[date_mask]\n",
        "X_test, y_test = X.loc[~date_mask], y.loc[~date_mask]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzlSMQG95-QR"
      },
      "source": [
        "# III. Establish Baseline\n",
        "\n",
        "**Task 5:** Since this is a **classification** problem, you should establish a baseline accuracy score. Figure out what is the majority class in `y_train` and what percentage of your training observations it represents. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNSermoB5-QR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4352fe44-660e-470e-fce9-9069e54a216f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    223\n",
            "1    160\n",
            "Name: Great, dtype: int64\n",
            "Baseline Accuracy Score: 0.5822454308093995\n"
          ]
        }
      ],
      "source": [
        "#print(y_train.value_counts())\n",
        "model_b = DummyClassifier(strategy=\"prior\").fit(X_train, y_train)\n",
        "baseline_acc = model_b.predict_proba(X_train)[0][0] #first ranked prior prob. = baseline classf. prob.\n",
        "print('Baseline Accuracy Score:', baseline_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wm1vYQ35-QS"
      },
      "source": [
        "# IV. Build Model\n",
        "\n",
        "**Task 6:** Build a `Pipeline` named `model_logr`, and fit it to your training data. Your pipeline should include:\n",
        "\n",
        "- a `OneHotEncoder` transformer for categorical features, \n",
        "- a `SimpleImputer` transformer to deal with missing values, \n",
        "- a [`StandarScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) transfomer (which often improves performance in a logistic regression model), and \n",
        "- a `LogisticRegression` predictor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1D1QNxEX5-QS"
      },
      "outputs": [],
      "source": [
        "model_logr = make_pipeline(OneHotEncoder(use_cat_names=True), SimpleImputer(strategy=\"median\"), StandardScaler(), LogisticRegression()).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0CaVgTU5-QS"
      },
      "source": [
        "# IV. Check Metrics\n",
        "\n",
        "**Task 7:** Calculate the training and test accuracy score for `model_lr`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-P7-sGos5-QT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe14563e-c743-47e1-be4c-8474b3fd7844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MAE: 0.028720626631853787\n",
            "Test MAE: 0.21052631578947367\n"
          ]
        }
      ],
      "source": [
        "training_acc = mean_absolute_error(y_train, model_logr.predict(X_train))\n",
        "test_acc = mean_absolute_error(y_test, model_logr.predict(X_test))\n",
        "\n",
        "print('Training MAE:', training_acc)\n",
        "print('Test MAE:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRwPspMt5-QT"
      },
      "source": [
        "# V. Communicate Results\n",
        "\n",
        "**Task 8:** Create a horizontal barchart that plots the 10 most important coefficients for `model_lr`, sorted by absolute value.\n",
        "\n",
        "**Note:** Since you created your model using a `Pipeline`, you'll need to use the [`named_steps`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) attribute to access the coefficients in your `LogisticRegression` predictor. Be sure to look at the shape of the coefficients array before you combine it with the feature names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgrx6Eca5-QT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "9a451296-1c13-4b89-af11-ef503fb97512"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-200b99c80c27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create your horizontal barchart here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_logr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logisticregression'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#first row only for coef list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_logr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'onehotencoder'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtop_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtop_feat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"barh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_logr' is not defined"
          ]
        }
      ],
      "source": [
        "# Create your horizontal barchart here.\n",
        "cvals = model_logr.named_steps['logisticregression'].coef_[0] #first row only for coef list\n",
        "feat = model_logr.named_steps['onehotencoder'].get_feature_names()\n",
        "top_feat = pd.Series(cvals, index=feat).sort_values(key=abs, ascending=False)\n",
        "top_feat.head(10).plot(kind=\"barh\")\n",
        "plt.xlabel('Coefficient of Review')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Coefficients for Logistic Regression');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE8A7MTn5-QU"
      },
      "source": [
        "There is more than one way to generate predictions with `model_lr`. For instance, you can use [`predict`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression) or [`predict_proba`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression#sklearn.linear_model.LogisticRegression.predict_proba).\n",
        "\n",
        "**Task 9:** Generate predictions for `X_test` using both `predict` and `predict_proba`. Then below, write a summary of the differences in the output for these two methods. You should answer the following questions:\n",
        "\n",
        "- What data type do `predict` and `predict_proba` output?\n",
        "- What are the shapes of their different output?\n",
        "- What numerical values are in the output?\n",
        "- What do those numerical values represent?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODcbfJG45-QU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02601cab-ea72-4930-d259-0865fc93006f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "[1 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1\n",
            " 1] [[1.30978269e-05 9.99986902e-01]\n",
            " [1.15928074e-03 9.98840719e-01]\n",
            " [9.27050807e-01 7.29491931e-02]\n",
            " [5.19430700e-05 9.99948057e-01]\n",
            " [9.99468732e-01 5.31267871e-04]\n",
            " [9.70650781e-01 2.93492187e-02]\n",
            " [1.25907165e-02 9.87409284e-01]\n",
            " [5.09193495e-05 9.99949081e-01]\n",
            " [5.17410667e-05 9.99948259e-01]\n",
            " [1.26379879e-01 8.73620121e-01]\n",
            " [7.49522436e-01 2.50477564e-01]\n",
            " [9.68595228e-01 3.14047718e-02]\n",
            " [3.25365297e-01 6.74634703e-01]\n",
            " [2.93828757e-01 7.06171243e-01]\n",
            " [1.46123584e-02 9.85387642e-01]\n",
            " [5.27026575e-02 9.47297342e-01]\n",
            " [3.05465785e-02 9.69453421e-01]\n",
            " [9.98692234e-01 1.30776631e-03]\n",
            " [9.97489097e-01 2.51090342e-03]\n",
            " [9.99552207e-01 4.47793065e-04]\n",
            " [9.97058824e-01 2.94117596e-03]\n",
            " [4.76062381e-03 9.95239376e-01]\n",
            " [9.48880319e-01 5.11196815e-02]\n",
            " [3.71845067e-02 9.62815493e-01]\n",
            " [4.18149823e-01 5.81850177e-01]\n",
            " [9.29305781e-01 7.06942189e-02]\n",
            " [9.94801501e-01 5.19849853e-03]\n",
            " [1.83600468e-05 9.99981640e-01]\n",
            " [4.75030360e-02 9.52496964e-01]\n",
            " [2.74732892e-03 9.97252671e-01]\n",
            " [9.86658577e-01 1.33414231e-02]\n",
            " [1.87379890e-01 8.12620110e-01]\n",
            " [3.89884125e-03 9.96101159e-01]\n",
            " [9.98688300e-01 1.31169995e-03]\n",
            " [3.01250531e-01 6.98749469e-01]\n",
            " [2.13272273e-01 7.86727727e-01]\n",
            " [8.53610098e-05 9.99914639e-01]\n",
            " [1.07189057e-02 9.89281094e-01]]\n"
          ]
        }
      ],
      "source": [
        "# Write code here to explore the differences between `predict` and `predict_proba`.\n",
        "pred, pred_p = model_logr.predict(X_test), model_logr.predict_proba(X_test)\n",
        "print(type(pred), type(pred_p))\n",
        "print(pred, pred_p)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T-SQ4CZ5-QU"
      },
      "source": [
        "**Give your written answer here:**\n",
        "\n",
        "\n",
        "The predict method returns a vector of values, [0|1] for each entry in the matrix sent, corresponding to the classification the model makes for each entry. \n",
        "\n",
        "The predict_proba method instead returns a list of pairs corresponding to the model's probability that each entry is in the first or second category, represented by float values from 0 to 1\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "LS_DS_214_solution_JD.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}